# Changelog

**Recent releases for MCP Memory Service (v8.51.0 and later)**

All notable changes to the MCP Memory Service project will be documented in this file.

For older releases (v8.50.1 and earlier), see [CHANGELOG-HISTORIC.md](./CHANGELOG-HISTORIC.md).

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/), and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

## [9.0.3] - 2026-01-17

üö® **CRITICAL HOTFIX** - Fixes Cloudflare D1 schema migration bug causing container reboot loop

### Fixed
- **CRITICAL: Add automatic schema migration for Cloudflare D1 backend** (Issue #354)
  - **Root Cause**: v8.72.0 added `tags` and `deleted_at` columns but Cloudflare backend had no migration logic
  - **Impact**: Users upgrading from v8.69.0 ‚Üí v8.72.0+ experienced container reboot loop due to missing columns
  - **Symptoms**: `400 Bad Request` errors from D1 when trying to use missing columns
  - **Fix**: Added `_migrate_d1_schema()` method with automatic column detection and migration
  - **Fix**: Added retry logic with exponential backoff to handle D1 metadata sync issues
  - **Fix**: Added clear error messages with manual SQL workaround if automated migration fails
  - **Files Changed**:
    - `src/mcp_memory_service/storage/cloudflare.py:290-495` - Added migration methods
  - **Migration Process**:
    1. Check existing schema using `PRAGMA table_info(memories)`
    2. Add missing columns: `tags TEXT`, `deleted_at REAL DEFAULT NULL`
    3. Create index: `idx_memories_deleted_at`
    4. Verify columns are usable (handles D1 metadata sync issues)
  - **Backward Compatibility**: Safe for all versions (idempotent, no data loss)
  - **Manual Workaround** (if automated migration fails):
    ```sql
    ALTER TABLE memories ADD COLUMN tags TEXT;
    ALTER TABLE memories ADD COLUMN deleted_at REAL DEFAULT NULL;
    CREATE INDEX IF NOT EXISTS idx_memories_deleted_at ON memories(deleted_at);
    ```
  - **Recommendation**: All Cloudflare users on v8.72.0+ should upgrade to v9.0.3 immediately

## [9.0.2] - 2026-01-17

üö® **CRITICAL HOTFIX** - Actually includes the code fix from v9.0.1

### Fixed
- **CRITICAL: Include actual code changes for mass deletion bug fix**
  - **Issue**: v9.0.1 was tagged and released WITHOUT the actual code changes to `manage.py`
  - **Root Cause**: Code changes were committed AFTER the v9.0.1 tag was created
  - **Impact**: PyPI and Docker images for v9.0.1 do NOT contain the fix
  - **This Release**: v9.0.2 includes the actual code changes from commit 9c5ed87
  - **Files Fixed**:
    - `src/mcp_memory_service/web/api/manage.py:254` - `confirm_count` now REQUIRED
    - Added comprehensive security documentation and error messages
  - **Recommendation**: All users should upgrade to v9.0.2 (not v9.0.1)

## [9.0.1] - 2026-01-17

‚ö†Ô∏è **WARNING**: This release was tagged incorrectly and does NOT include the actual code fix. Please upgrade to v9.0.2 instead.

üö® **CRITICAL HOTFIX** - Fixes accidental mass deletion bug in v9.0.0

### Fixed
- **CRITICAL: Fix accidental mass deletion via /delete-untagged endpoint** (Hotfix)
  - **Root Cause**: `confirm_count` parameter was optional in `/api/manage/delete-untagged` endpoint
  - **Impact**: If endpoint called without `confirm_count`, ALL untagged memories were deleted without confirmation
  - **Incident**: On 2026-01-17 at 10:59:20, 6733 memories (87% of database) were accidentally soft-deleted
  - **Fix**: Made `confirm_count` parameter REQUIRED (not optional)
  - **Fix**: Enhanced safety check to always validate confirm_count matches actual count
  - **Fix**: Improved error message to guide users to use GET /api/manage/count-untagged first
  - **Security**: Added comprehensive documentation about the security implications
  - **Recovery**: All affected memories can be restored by setting `deleted_at = NULL`
  - **File**: `src/mcp_memory_service/web/api/manage.py:254`
  - **Breaking Change**: API now requires `confirm_count` parameter (previously optional)
  - **Recommendation**: All v9.0.0 users should upgrade immediately to v9.0.1

## [9.0.0] - 2026-01-17

‚ö†Ô∏è **MAJOR RELEASE** - Contains breaking changes. See Migration Guide in README.md.

### Fixed
- **Fix 33 API/HTTP test failures with package import error** (Issue #351, PR #352)
  - Changed relative imports to absolute imports in `web/api/backup.py` for pytest compatibility
  - Fixed `ModuleNotFoundError: 'mcp_memory_service' is not a package` during test collection
  - Resolved pytest `--import-mode=prepend` confusion with triple-dot relative imports
  - **Test Results**: 829/914 tests passing (up from 818), all API/HTTP integration tests pass
  - **Impact**: Single-line fix, no API changes, no breaking changes

- **Fix validation tests and legacy type migration** (PR #350)
  - Fixed all 5 validation tests (editable install detection, version matching, runtime warnings)
  - Fixed `check_dev_setup.py` to import `_version.py` directly instead of text parsing
  - Fixed timestamp test import error (namespace collision in `models` import)
  - Migrated 38 legacy memory types to new ontology (task‚Üíobservation, note‚Üíobservation, standard‚Üíobservation)
  - Pinned `numpy<2` for pandas compatibility (prevents binary incompatibility errors)
  - Extracted offline mode setup to standalone `offline_mode.py` module (cleaner package structure)
  - Restored core imports in `__init__.py` for pytest package recognition
  - Updated consolidation retention periods for new ontology types
  - **Test Results**: 818/851 tests passing (96%), all validation tests pass

- **Fix bidirectional storage for asymmetric relationships** ‚ö†Ô∏è **BREAKING CHANGE** (Issue #348, PR #349)
  - Asymmetric relationships (causes, fixes, supports, follows) now store only directed edges
  - Symmetric relationships (related, contradicts) continue storing bidirectional edges
  - Database migration (010) removes incorrect reverse edges from existing data
  - Query infrastructure with `direction` parameter now works correctly with asymmetric storage
  - SemanticReasoner methods (find_causes, find_fixes) validated with new storage model
  - New `is_symmetric_relationship()` function in ontology.py for relationship classification
  - Updated `store_association()` to conditionally store edges based on relationship symmetry
  - Updated `find_connected()` direction="both" to use CASE expression for asymmetric edges
  - **Breaking Change**: Code expecting bidirectional asymmetric edges needs `direction="both"` parameter

### Added
- **Phase 0 Ontology Foundation - Core Implementation** ‚ö†Ô∏è **BREAKING CHANGE** (PR #347)
  - **Memory Type Ontology**: Formal classification system with 5 base types and 21 subtypes
    - Base types: observation, decision, learning, error, pattern
    - Hierarchical taxonomy with parent-child relationships
    - Soft validation: defaults to 'observation' for invalid types (backward compatible)
  - **Tag Taxonomy**: Structured namespace system with 6 predefined namespaces
    - Namespaces: `sys:`, `q:`, `proj:`, `topic:`, `t:`, `user:`
    - Backward compatible with legacy tags (no namespace)
    - O(1) namespace validation via exposed `VALID_NAMESPACES` class attribute
  - **Typed Relationships**: Semantic relationship system for knowledge graph
    - 6 relationship types: causes, fixes, contradicts, supports, follows, related
    - Database migration adds `relationship_type` column to memory_graph table
    - `TypedAssociation` dataclass for explicit relationship semantics
    - GraphStorage extended with relationship type filtering in queries
  - **Lightweight Reasoning Engine**: Foundation for causal inference
    - `SemanticReasoner` class with contradiction detection
    - Causal chain analysis: `find_fixes()`, `find_causes()`
    - Placeholder methods for future reasoning capabilities
  - **Performance Optimizations**: Caching and validation improvements
    - `get_all_types()`: 97.5x speedup via module-level caching
    - `get_parent_type()`: 35.9x speedup via cached reverse lookup map
    - Tag validation: 47.3% speedup (eliminated double parsing)
  - **Security Improvements**: Template-based SQL query building
  - **Testing**: 80 comprehensive tests with 100% backward compatibility
  - **Breaking Change**: Legacy types (task, note, standard) deprecated, auto-migrate with `scripts/migrate_ontology.py`

- **Response Size Limiter** (PR #344)
  - Added `max_response_chars` parameter to 5 memory retrieval tools to prevent context window overflow
  - Tools updated: `retrieve_memory`, `recall_memory`, `retrieve_with_quality_boost`, `search_by_tag`, `recall_by_timeframe`
  - Environment variable: `MCP_MAX_RESPONSE_CHARS` (default: 0 = unlimited)
  - Truncates at memory boundaries (never mid-content) to preserve data integrity
  - Always returns at least one memory even if it exceeds the character limit
  - Displays truncation warning with shown/total counts when limit is applied
  - New utility module: `src/mcp_memory_service/server/utils/response_limiter.py` (260 lines)
  - Comprehensive test coverage: 29 tests (415 lines) covering edge cases
  - Recommended values: 30000-50000 characters for typical LLM context windows
  - Backward compatible: existing code continues to work with unlimited responses

## [8.76.0] - 2026-01-12

### Added
- **Official Lite Distribution Support** (PR #341)
  - **New Package**: `mcp-memory-service-lite` - Official lightweight distribution for ONNX-only installations
    - 90% installation size reduction: 7.7GB ‚Üí 805MB
    - Same nvidia-quality-classifier-deberta ONNX model, just lighter dependency chain
    - Faster installation time: <2 minutes vs 10-15 minutes
  - **Dual Package Publishing**: Automated CI/CD workflow (`publish-dual.yml`) publishes both packages to PyPI
    - Full package: `mcp-memory-service` (includes transformers, torch, sentence-transformers)
    - Lite package: `mcp-memory-service-lite` (ONNX-only, tokenizers-based embeddings)
    - Both packages share the same codebase via pyproject-lite.toml
  - **Conditional Dependency Loading**: Transformers becomes truly optional
    - Quality scoring works with tokenizers-only (lite) or full transformers (full package)
    - Graceful fallback: embedding service detects available packages and loads accordingly
    - No runtime performance impact - same quality scoring performance
  - **Implementation Details**:
    - Created `pyproject-lite.toml` with minimal dependencies (no transformers/torch)
    - Updated `onnx_ranker.py` to use tokenizers directly instead of transformers
    - Fixed quality_provider metadata access bug in async_scorer.py
    - 15 comprehensive integration tests (`tests/test_lightweight_onnx.py`, 487 lines)
  - **Documentation**:
    - Complete setup guide: `docs/LIGHTWEIGHT_ONNX_SETUP.md`
    - Setup script: `scripts/setup-lightweight.sh`
  - **Use Cases**:
    - CI/CD pipelines (faster builds, lower disk usage)
    - Resource-constrained environments (VPS, containers)
    - Quick local development setup
    - Users who only need quality scoring (not full ML features)
- **Production Refactor Command**: Added `/refactor-function-prod` command for production-ready code refactoring
  - Enhanced version of the refactor-function PoC with production features
- **Refactoring Metrics Documentation**: Comprehensive Issue #340 refactoring documentation in `.metrics/`
  - Baseline complexity measurements
  - Complexity comparison showing 75.2% average reduction
  - Tracking tables and completion reports

### Fixed
- **Multi-Protocol Port Detection and Cross-Platform Fallback** (`scripts/service/http_server_manager.sh`)
  - **Problem**: Update script failed with port conflict on Linux systems without lsof installed
  - **Root Causes**:
    - Script used lsof exclusively for port detection, silently failed on systems without it (common on Arch/Manjaro)
    - Health checks only tried HTTP protocol, failed when server used HTTPS
    - Led to "server not running" false positive ‚Üí attempted restart ‚Üí port conflict error
  - **Solution**:
    - Implemented 4-level port detection fallback chain: lsof ‚Üí ss ‚Üí netstat ‚Üí ps
    - Health check now tries both HTTP and HTTPS protocols with automatic fallback
    - Explicit error messages when all detection methods fail
    - Cross-platform compatibility validated on Arch Linux with ss-only environment
  - **Testing**: Manual testing on Arch Linux without lsof, confirmed fallback to ss works correctly
  - **Impact**: Resolves installation failures on minimal Linux distributions, improves HTTPS deployment reliability
- **MCP HTTP Transport**: Fix KeyError 'backend_info' in get_cache_stats tool (Issue #342, PR #343)
  - **Problem**: `get_cache_stats` tool crashed with `KeyError: 'backend_info'` when called via HTTP transport
  - **Root Cause**: Code tried to set `result["backend_info"]["embedding_model"]` without creating the dict first
  - **Solution**: Create complete `backend_info` dict with all required fields (storage_backend, sqlite_path, embedding_model)
  - **Impact**: HIGH severity (tool completely broken in HTTP transport), LOW risk fix
  - **Testing**: Added regression test validating backend_info structure
  - Thanks to @Sundeepg98 for reporting with clear reproduction steps!
- **Hook Installer**: Auto-register PreToolUse hook in settings.json (Issue #335)
  - **Problem**: `permission-request.js` was copied but never registered in `settings.json`, so the hook never executed
  - **Solution**: Installer now auto-adds PreToolUse hook configuration for MCP permission management
  - Added 7 new safe patterns: `store`, `remember`, `ingest`, `rate`, `proactive`, `context`, `summary`, `recommendations`
  - Hook now correctly auto-approves additive operations (e.g., `store_memory`)
- **Memory Hooks**: Fix cluster memory categorization showing incorrect dates
  - **Problem**: Consolidated cluster memories (from consolidation system) showed "üïí today" in "Recent Work" section because hook used `created_at` (when cluster was created) instead of `temporal_span` (time period the cluster represents)
  - **Solution**: Added new "üì¶ Consolidated Memories" section with proper temporal span display (e.g., "üìÖ 180d span")
  - **Changes**: Updated `claude-hooks/utilities/context-formatter.js` to detect `compressed_cluster` memory type and display `metadata.temporal_span.span_days`
  - **Impact**: Prevents confusion between recent development and historical memory summaries

### Changed
- **Hook Installer**: Refactored MCP configuration detection functions for improved maintainability (Issue #340)
  - Reduced complexity by 45.5% across 3 core functions
  - Extracted 6 well-structured helper functions (avg complexity 3.83)
  - Fixed validation bug: Added 'detected' server type support (PR #339 follow-up)
  - Improved code grade distribution: 58% A-grade functions (up from 53%)
- **Memory Consolidation**: Improved cluster concept quality with intelligent deduplication
  - **Problem**: Cluster summaries showed redundant concepts (e.g., "memories, Memories, MEMORY, memory") and noise (SQL keywords like "BETWEEN")
  - **Solution**: Added case-insensitive deduplication and filtering of SQL keywords/meta-concepts
  - **Changes**: Enhanced `_extract_key_concepts()` in `consolidation/compression.py` to deduplicate case variants and filter 10 SQL keywords + 6 meta-concepts
  - **Impact**: Cluster summaries now show meaningful thematic concepts instead of technical noise

## [8.75.1] - 2026-01-10

### Fixed
- **Hook Installer**: Support flexible MCP server naming conventions (PR #339)
  - **Problem**: Installer required exact server name `memory`, causing installation failures for users with custom MCP configurations (e.g., `mcp-memory-service`, `memory-service`)
  - **Solution**:
    - Installer now detects servers matching patterns: `memory`, `mcp-memory`, `*memory*service*`, `*memory*server*`
    - Backward compatible with existing `memory` server name
    - Provides clear error messages when no matching server found
    - Improved user experience for custom MCP configurations
  - **Testing**: Manual testing with various server name configurations
  - **Contributors**: Thanks to @timkjr for reporting and testing the fix!

## [8.75.0] - 2026-01-09

### Added
- **Lightweight ONNX Quality Scoring without Transformers Dependency** (PR #337)
  - **Problem**: transformers package adds 6.9GB of dependencies (torch, tensorflow, etc.), making installation bloated for users who only need quality scoring
  - **Solution**: Use tokenizers package directly instead of transformers
    - 90% disk space reduction: 7.7GB ‚Üí 805MB total installation
    - Same ONNX model (nvidia-quality-classifier-deberta), just lighter dependency chain
    - Conditional dependency loading - only install what you use
  - **Implementation**:
    - Modified `src/mcp_memory_service/quality/onnx_ranker.py` to use tokenizers directly
    - Added tokenizers as optional dependency in pyproject.toml
    - Updated embedding service to handle both tokenizers and transformers (graceful fallback)
    - Fixed quality_provider metadata access bug in async_scorer.py
  - **Testing**: 15 comprehensive integration tests (`tests/test_lightweight_onnx.py`, 487 lines)
  - **Documentation**:
    - Complete setup guide: `docs/LIGHTWEIGHT_ONNX_SETUP.md`
    - Setup script: `scripts/setup-lightweight.sh`
  - **Benefits**:
    - Faster installation (<2 min vs 10-15 min)
    - Lower disk usage (805MB vs 7.7GB)
    - Same quality scoring performance
    - No runtime performance impact

### Fixed
- **Multi-Protocol and Cross-Platform Port Detection** (`scripts/service/http_server_manager.sh`)
  - **Problem**: Update script failed with port conflict on Linux systems without lsof installed
  - **Root Cause**:
    - Script used lsof exclusively, silently failed on systems without it (common on Arch/Manjaro)
    - Health checks only tried HTTP, failed when server used HTTPS
    - Led to "server not running" false positive ‚Üí port conflict
  - **Solution**:
    - Port detection fallback chain: lsof ‚Üí ss ‚Üí netstat ‚Üí ps
    - Health check supports both HTTP and HTTPS protocols with automatic fallback
    - Tested on Arch Linux with ss-only environment
  - **Fixes**: Issue #341

## [8.74.0] - 2026-01-09

### Added
- **Cross-Platform Wrapper Scripts for Orphan Process Cleanup** (`scripts/run/`)
  - **Python Wrapper** (`memory_wrapper_cleanup.py`): Universal cross-platform solution (recommended)
  - **Bash Wrapper** (`memory_wrapper_cleanup.sh`): Native macOS/Linux implementation
  - **PowerShell Wrapper** (`memory_wrapper_cleanup.ps1`): Native Windows implementation
  - **Automatic Orphan Detection**: Identifies orphaned MCP memory processes when Claude Desktop/Code crashes
    - Unix: Detects processes adopted by init/launchd (ppid == 1)
    - Windows: Detects processes whose parent no longer exists
  - **Database Lock Prevention**: Cleans up orphaned processes before starting new server instance
  - **Safe Cleanup**: Only terminates actual orphans, preserves active sessions
  - **Comprehensive Documentation** (`README_CLEANUP_WRAPPER.md`): Installation guide, troubleshooting, and technical details
  - **Fixes**: SQLite "database is locked" errors when running multiple Claude instances after crashes

## [8.73.0] - 2026-01-09

### Added
- **Universal Permission Request Hook v1.0** (`claude-hooks/core/permission-request.js`)
  - **Automatic MCP Tool Permission Management**: Eliminates repetitive permission prompts for safe operations
  - **Safe-by-Default Design**: Auto-approves read-only operations (get, list, retrieve, search, query, etc.)
  - **Destructive Operation Protection**: Requires confirmation for write/delete operations (delete, update, execute, etc.)
  - **Universal MCP Server Support**: Works across all MCP servers (memory, browser, context7, playwright, etc.)
  - **Zero Configuration**: Works out of the box with sensible defaults
  - **Extensible Pattern Matching**: Configure custom patterns via `claude-hooks/config.json`
  - **Comprehensive Documentation**: Installation guide, configuration reference, and troubleshooting
  - **Installer Integration**: Added to core hooks installation via `install_hooks.py`
- **Sync Status Maintenance Script** (`scripts/maintenance/sync_status.py`)
  - Compares local SQLite database with Cloudflare D1
  - Shows memory counts (total, active, tombstones) for both databases
  - Identifies sync discrepancies: local-only, D1-only, pending deletions
  - Cross-platform support (Windows, macOS, Linux)
  - Handles schema differences gracefully

### Fixed
- **Cloudflare D1 Schema Missing Columns** (`src/mcp_memory_service/storage/cloudflare.py`)
  - **Problem**: D1 schema was missing `deleted_at` and `tags` columns, causing soft-delete operations to fail silently
  - **Impact**: Tombstone-based sync between devices was broken - deleted memories on one device were not synced to others
  - **Fix**: Added `deleted_at REAL DEFAULT NULL` and `tags TEXT` columns to D1 schema
  - **Index**: Added `idx_memories_deleted_at` index for query performance

## [8.72.0] - 2026-01-08

### Added
- **Graph Traversal MCP Tools** (PR #332)
  - **Feature**: Three new MCP tools for querying memory association graph directly
  - **Tools**:
    - `find_connected_memories` - Multi-hop connection discovery (5ms, 30x faster than tag search)
    - `find_shortest_path` - BFS pathfinding between two memories (15ms)
    - `get_memory_subgraph` - Subgraph extraction for visualization (25ms)
  - **Implementation**:
    - New handler module: `src/mcp_memory_service/server/handlers/graph.py` (380 lines)
    - Integration: `server_impl.py` tool registration and routing (134 lines)
    - Graceful fallback if `memory_graph` table unavailable
  - **Testing**: 10 comprehensive tests with 100% handler coverage (`tests/test_graph_traversal.py`, 328 lines, 58 assertions)
  - **Validation**: `scripts/validation/validate_graph_tools.py` for MCP schema and query correctness
  - **Quality Metrics**:
    - Health Score: 85/100 (EXCELLENT)
    - Complexity: Average 4.5 (Grade A)
    - Security: 0 vulnerabilities
  - **Benefits**:
    - 30x performance improvement over tag-based connected memory search
    - Enables Claude Code to traverse memory associations directly via MCP
    - Supports exploration of knowledge relationships and context chains

## [8.71.0] - 2026-01-06

### Added
- **Memory Management APIs and Graceful Shutdown** (PR #331)
  - **Problem**: Orphaned MCP sessions consuming excessive memory (reported in Discussion #331)
  - **Cache Cleanup Functions** (`src/mcp_memory_service/services/cache_manager.py`):
    - `clear_all_caches()` - Clear storage and service caches
    - `get_memory_usage()` - Get process memory statistics (RSS, VMS, available memory)
    - `get_cache_stats()` - Get cache hit/miss statistics
  - **Model Cache Cleanup** (`src/mcp_memory_service/storage/sqlite_vec.py`):
    - `clear_model_caches()` - Clear embedding model caches
    - `get_model_cache_stats()` - Get model cache statistics
  - **Graceful Shutdown** (`src/mcp_memory_service/server/server_impl.py`):
    - `_cleanup_on_shutdown()` - Cleanup function for signal handlers
    - Updated `shutdown()` method with proper cache and connection cleanup
    - Added `atexit` handler for normal process exit
    - SIGTERM and SIGINT handlers now call cleanup before exit
  - **Memory Management API Endpoints** (`src/mcp_memory_service/api/routes/health.py`):
    - `GET /api/memory-stats` - Get detailed memory usage (process memory + cache stats + model cache stats)
    - `POST /api/clear-caches` - Clear all caches manually (returns memory freed)
  - **Documentation**:
    - New file: `docs/troubleshooting/memory-management.md` - Comprehensive guide for monitoring and managing memory
  - **Benefits**:
    - Prevents memory leaks from orphaned sessions
    - Enables proactive memory monitoring and cleanup
    - Graceful resource release on server shutdown
    - Production-ready memory management for long-running deployments

## [8.70.0] - 2026-01-05

### Added
- **User Override Commands for Memory Hooks** (`~/.claude/hooks/utilities/user-override-detector.js`)
  - **Feature**: New `#skip` and `#remember` commands give users manual control over automatic memory triggers
  - **Implementation**:
    - Shared detection module for consistent behavior across all hooks
    - `#skip` - Bypasses memory retrieval in session-start hook
    - `#remember` - Forces mid-conversation analysis (bypasses cooldown) or session-end consolidation (bypasses thresholds)
    - Applied to: `session-start.js`, `mid-conversation.js`, `session-end.js`
  - **Configuration**: New `applyTo` array in `config.json` defines which hooks are active
  - **Documentation**: Updated `README.md` with "User Overrides" section and `README-AUTO-CAPTURE.md` with comprehensive supported hooks table
  - **Use Cases**:
    - Skip retrieval when starting fresh conversation (`#skip`)
    - Force memory capture of important mid-session insights (`#remember`)
    - Override 100-character threshold for critical session notes (`#remember`)

### Added (from v8.69.1-dev)
- **Automatic Test Memory Cleanup System** (`tests/conftest.py`, `tests/api/test_operations.py`)
  - **Problem**: Test memories polluted production database (106+ orphaned test memories found)
  - **Solution**: Tag-based cleanup system
    - Reserved `__test__` tag for all test-created memories
    - New `test_store` fixture auto-tags memories for cleanup
    - `pytest_sessionfinish` hook automatically deletes tagged memories at end of test session
    - New `delete_by_tag()` function in Code Execution API
  - **Result**: 92 test memories automatically cleaned after test run
  - **Migration**: Tests using `store()` should migrate to `test_store()` fixture

### Fixed (from v8.69.1-dev)
- **PowerShell Update Script Git Stderr Handling** (`update_and_restart.ps1`)
  - **Problem**: Script failed with `NativeCommandError` during `git pull --rebase`
  - **Root Cause**: Git writes informational messages to stderr even on success (e.g., "From github.com:..."), and `$ErrorActionPreference = "Stop"` treats any stderr as error
  - **Solution**: Temporarily set `ErrorActionPreference = "Continue"` during git pull, then check `$LASTEXITCODE` for actual errors

## [8.69.0] - 2026-01-04

### Added
- **MCP Tool Annotations for Improved LLM Decision-Making** (contributed by @triepod-ai)
  - Added `readOnlyHint`, `destructiveHint`, and `title` annotations to all 24 MCP tools
  - **Read-only tools** (12): `retrieve_memory`, `recall_memory`, `search_by_tag`, `check_database_health`, `get_cache_stats`, etc.
  - **Destructive tools** (9): `delete_memory`, `update_memory_metadata`, `cleanup_duplicates`, `rate_memory`, etc.
  - **Additive-only tools** (3): `store_memory`, `ingest_document`, `ingest_directory` (marked with `destructiveHint: false`)
  - Bumped MCP SDK dependency from `>=1.0.0` to `>=1.8.0` for annotation support
  - Enables MCP clients to auto-approve safe read-only operations and prompt for confirmation on destructive actions
  - PR #328 by @triepod-ai

## [8.68.2] - 2026-01-04

### Added
- **Platform Detection Helper Documentation** (`scripts/utils/README_detect_platform.md`)
  - Comprehensive guide for platform detection helper
  - JSON output format documentation
  - Supported platforms comparison table
  - Integration details with `update_and_restart.sh`
  - Example outputs for different hardware configurations

### Fixed
- **Platform Detection Improvements - Hardware Acceleration** (`update_and_restart.sh`, `detect_platform.py`)
  - **Problem**: Apple Silicon M1/M2/M3 Macs used CPU-only PyTorch instead of Metal Performance Shaders (MPS)
  - **Impact**: Significant performance loss on M-series Macs (embedding generation 3-5x slower)
  - **Root Cause**: Old bash-only detection treated all macOS as CPU-only, no MPS/ROCm/DirectML support
  - **Solution**:
    - Enhanced `update_and_restart.sh` with comprehensive hardware detection (MPS, CUDA, ROCm, DirectML, CPU)
    - Created `scripts/utils/detect_platform.py` using shared `gpu_detection.py` module for consistency
    - Python-based detection provides optimal PyTorch index selection per platform
    - Graceful fallback to old logic if Python helper unavailable
  - **Benefits**:
    - MPS support for Apple Silicon (native Metal acceleration)
    - CUDA version-specific PyTorch (cu121, cu118, cu102)
    - ROCm support for AMD GPUs (rocm5.6)
    - DirectML support for Windows GPU acceleration
    - Consistent with `install.py` detection logic

## [8.68.1] - 2026-01-03

### Fixed
- **üî¥ CRITICAL: Soft-Deleted Memories Syncing from Cloudflare** (Hybrid Backend Data Integrity Issue)
  - **Problem**: Soft-deleted memories from Cloudflare were incorrectly syncing back to local SQLite databases
  - **Impact**: Hybrid backend users experienced "ghost memories" that should have been deleted
  - **Root Cause**: 5 Cloudflare methods (`search_memories`, `search_by_tag`, `search_by_timeframe`, `list_memories`, `get_all_memories`) were missing `deleted_at IS NULL` filter
  - **Solution**:
    - Added `deleted_at IS NULL` filter to all 5 Cloudflare query methods
    - Defense-in-depth check in `hybrid.py` sync logic to filter soft-deleted records
  - **Files Changed**: `cloudflare.py` (5 methods), `hybrid.py` (sync validation)
  - **Test Updates**: Fixed `test_cleanup_duplicates` to verify soft-delete behavior
- **Update Script Improvements** (`scripts/update_and_restart.sh`, `update_and_restart.ps1`)
  - Support HTTPS in health check verification
  - Improved UX with better progress messages
  - Prevent unnecessary CUDA package downloads
- **PowerShell Script Enhancements** (`update_and_restart.ps1`)
  - SSH agent integration for Git authentication
  - Unicode to ASCII conversion for compatibility
  - Better error handling for network operations

### Added
- **Database Transfer & Migration Troubleshooting Guide** (`docs/troubleshooting/database-transfer-migration.md`)
  - **SQLite-vec Corruption During Transfer**: Comprehensive guide for handling "database disk image is malformed" errors
    - **Root Cause**: sqlite-vec extension binary format incompatibility during SCP/rsync transfers
    - **Solution**: Use tar+gzip for all cross-platform transfers
    - **Detailed Steps**: Source archive creation ‚Üí transfer ‚Üí extraction ‚Üí verification
  - **Web Dashboard vs CLI Export Format Incompatibility**
    - Documents two export formats: Web Dashboard (`export_date`) vs CLI (`export_metadata`)
    - Import script now auto-detects and normalizes both formats (as of v8.68.0)
  - **Schema Migration Verification**
    - Diagnosis for "no such column: m.tags" errors
    - Manual migration scripts for tags column from metadata
  - **Backup Best Practices**: Verification checklist and cross-platform transfer protocols

### Changed
- **Import Script Enhanced Format Detection** (`scripts/sync/import_memories.py`)
  - Now accepts both Web Dashboard and CLI export formats
  - Auto-normalizes Web Dashboard format to CLI format for processing
  - Maintains backward compatibility with existing CLI exports
- **CLAUDE.md**: Added backup transfer warning in Essential Commands table with link to troubleshooting guide
- **hooks-quick-reference.md**: Added cross-reference to database transfer troubleshooting guide

### Fixed
- **Python 3.14 Compatibility in Update Script** (`scripts/update_and_restart.sh`)
  - **Problem**: Script failed on systems with Python 3.14 as default (PyO3/tokenizers incompatibility)
  - **Solution**: Auto-detect Python version and use compatible Python (3.12/3.13) for venv
  - **Features**:
    - `find_compatible_python()` searches for python3.12, 3.13, 3.11, 3.10
    - Auto-recreates venv when incompatible Python detected
    - Uses venv pip instead of system uv to avoid version conflicts
    - `.python312_compat` marker prevents unnecessary venv recreation
  - **Impact**: Script now works on bleeding-edge systems with Python 3.14

## [8.68.0] - 2026-01-03

### Added
- **Update & Restart Automation** - One-command workflow for all platforms
  - `scripts/update_and_restart.sh` (macOS/Linux) - Automated git pull ‚Üí pip install ‚Üí server restart
  - `scripts/service/windows/update_and_restart.ps1` (Windows PowerShell) - Windows equivalent
  - **Features**:
    - Automatic git pull with conflict detection
    - Auto-stash uncommitted changes with `--force` flag
    - Editable install (`pip install -e .`) with verification
    - Health check with 30s timeout
    - Version verification (git SHA + Python package version)
    - Color-coded output for better visibility
  - **Options**:
    - `--no-restart` - Update code only (skip server restart)
    - `--force` - Auto-stash uncommitted changes without prompting
  - **Impact**: 87% time reduction (15+ min manual workflow ‚Üí <2 min automated)
  - **Prevents Common Errors**: Forgotten `pip install -e .`, wrong server mode, stale imports
  - **Documentation**: Added prominent "Quick Update & Restart" sections to CLAUDE.md and README.md

  ![Update & Restart Script Demo](docs/images/update-restart-demo.png)
  *One-command update workflow: git pull ‚Üí dependency install ‚Üí version verification in 16 seconds*

### Changed
- **CLAUDE.md**: Added "Quick Update & Restart" section with cross-platform automation scripts (RECOMMENDED workflow)
- **README.md**: Added "Quick Commands" section under Setup & Installation highlighting automation scripts

## [8.67.0] - 2026-01-03

### Fixed
- **CRITICAL: Hybrid Backend Memory Resurrection Bug**
  - **Problem**: Deleted memories reappeared after sync in hybrid backend
  - **Root Cause**: Hard DELETE statements in Cloudflare backend removed records locally but memories still existed in cloud ‚Üí sync restored them
  - **Fixes Implemented**:
    1. **Cloudflare Backend** (`src/mcp_memory_service/storage/cloudflare.py`)
       - Line 793: `delete()` method - Changed hard DELETE to soft UPDATE with `deleted_at` timestamp
       - Line 1050: `cleanup_duplicates()` - Changed hard DELETE to soft UPDATE with `deleted_at`
    2. **SQLite-vec Backend** (`src/mcp_memory_service/storage/sqlite_vec.py`)
       - Line 2177: `get_all_memories()` - Added `WHERE deleted_at IS NULL` filter
       - Line 2394: `get_all_memories()` with params - Added tombstone filtering
       - Line 1698: `cleanup_duplicates()` - Changed hard DELETE to soft UPDATE
    3. **Dashboard API** (`src/mcp_memory_service/web/api/manage.py`)
       - Line 231: `count_untagged_memories()` - Added `AND deleted_at IS NULL` filter
       - Line 264: `delete_untagged_memories()` - Changed from hard DELETE to soft UPDATE
  - **Impact**:
    - 100% soft delete compliance across all backends
    - Dashboard shows consistent counts (no tombstone leakage)
    - All delete operations create tombstones that properly sync across devices
    - No more memory resurrections in hybrid backend
  - **Testing**: Cleaned up 132 test memories (soft-deleted with tombstones)

## [8.66.0] - 2026-01-02

### Fixed
- **Quality System - User Ratings Persistence** (Issue #325)
  - **Problem**: `rate_memory` showed success but ratings were not persisted to database
  - **Root Cause**: Handler passed entire metadata dict (with tags as string) to `update_memory_metadata()`, which expects tags as list ‚Üí silent failure
  - **Fix**: Only pass quality-related fields (quality_score, user_rating, user_feedback, etc.) and check return value
  - **Impact**: User ratings now persist correctly to database
  - **File**: `src/mcp_memory_service/server/handlers/quality.py`

- **Storage Backend - Time-based Deletion Methods** (Issue #323)
  - **Problem**: Handlers existed but storage methods were missing from all backends, causing AttributeError
  - **Implementation**:
    - Added `delete_by_timeframe(start_date, end_date, tag)` to all backends
    - Added `delete_before_date(before_date, tag)` to all backends
    - SQLite-vec: Uses soft-delete for tombstone support
    - Cloudflare: D1 batch queries with proper retry patterns
    - Hybrid: Delegates to SQLite + queues for sync with Cloudflare
  - **Impact**: Time-based memory cleanup now works across all storage backends
  - **Files**: `src/mcp_memory_service/storage/{base,sqlite_vec,cloudflare,hybrid}.py`

- **Debug Tool - Backend-Agnostic Exact Match** (Issue #324)
  - **Problem**: `exact_match_retrieve()` used ChromaDB-specific API, causing empty results with SQLite-vec
  - **Implementation**:
    - Added `get_by_exact_content(content)` method to all storage backends
    - SQLite-vec: SQL WHERE content = ? AND deleted_at IS NULL
    - Cloudflare: D1 query with retry patterns
    - Hybrid: Delegates to primary storage
    - Three-tier fallback in debug.py for backwards compatibility
  - **Impact**: Debug tool now works with all storage backends
  - **Files**: `src/mcp_memory_service/storage/{base,sqlite_vec,cloudflare,hybrid}.py`, `src/mcp_memory_service/utils/debug.py`

## [8.65.0] - 2026-01-02

### Added
- **Memory Maintenance Scripts** (5 new utilities in `scripts/maintenance/`)
  - `auto_retag_memory.py` - Auto-tag single memory with complete tag replacement
  - `auto_retag_memory_merge.py` - Auto-tag with merge (preserves specific tags)
  - `delete_test_memories.py` - Bulk delete test memories with confirmation
  - `retag_valuable_memories.py` - Bulk retag valuable untagged memories
  - `cleanup_memories.py` - Rewritten classifier for test vs valuable memories (HTTP-API based)
  - **Impact**: Easier memory hygiene workflows for large datasets

- **Documentation Updates**
  - `AGENTS.md` - New server management and cleanup commands reference
  - `README.md` - New "Memory Maintenance & Cleanup" section with workflows
  - **Impact**: Better discoverability of maintenance capabilities

### Fixed
- **Hybrid Sync Performance** (5x speedup)
  - **Issue**: Hard-coded `batch_size=10` limit in `hybrid.py` ignored `.env` configuration
  - **Fix**: Removed override, now respects `MCP_HYBRID_BATCH_SIZE` (default: 50)
  - **Impact**: 5x faster bulk operations (50 vs 10 concurrent requests)
  - **Real-world**: Resolved stuck sync with 746 deletion queue
  - **File**: `src/mcp_memory_service/storage/hybrid.py:1036`

- **Schema Migration on Existing Databases**
  - **Issue**: `deleted_at` column migration only ran on fresh installs
  - **Fix**: Migration now runs unconditionally on startup for all databases
  - **Impact**: Ensures tombstone support works on existing installations
  - **File**: `src/mcp_memory_service/storage/sqlite_vec.py`

### Changed
- **Test Infrastructure**
  - Added `.coveragerc` with exclusions for infrastructure code
  - Improved coverage reporting accuracy

## [8.64.0] - 2026-01-02

### Added
- **Tombstone Support for Hybrid Sync** (Race Condition Fix)
  - **Problem**: Memories deleted on one device reappeared after syncing from another device
  - **Root Cause**: No tombstone records - deleted memories were pulled back from cloud as "missing"
  - **Solution**: Soft-delete with `deleted_at` column instead of hard DELETE

- **Soft-Delete Implementation** (`storage/sqlite_vec.py`)
  - `delete()` now sets `deleted_at` timestamp instead of removing row
  - `delete_by_tag()` and `delete_by_tags()` use soft-delete
  - `is_deleted(content_hash)` checks if memory was soft-deleted
  - `purge_deleted(older_than_days=30)` permanently removes old tombstones
  - All SELECT queries updated to exclude deleted records (`WHERE deleted_at IS NULL`)

- **Schema Migration** (`sqlite_vec.py:531-546`)
  - Auto-adds `deleted_at REAL DEFAULT NULL` column on startup
  - Creates `idx_deleted_at` index for fast exclusion queries
  - Non-breaking: existing memories have NULL (not deleted)

- **Tombstone Check in Hybrid Sync** (`hybrid.py:1015-1024`)
  - Before syncing "missing" memory from cloud, checks `is_deleted()`
  - If locally deleted, skips sync and propagates deletion to cloud
  - Prevents race condition where delete and sync overlap

- **Automatic Tombstone Purge** (`hybrid.py:508-526`)
  - `BackgroundSyncService` runs daily purge of tombstones >30 days old
  - Configurable via `TOMBSTONE_RETENTION_DAYS` environment variable
  - Stats tracked in `sync_stats['tombstones_purged']`

- **Base Class Updates** (`storage/base.py:251-287`)
  - `is_deleted()` with default implementation returning False
  - `purge_deleted()` with default implementation returning 0
  - Backends without soft-delete support continue working unchanged

### Fixed
- **Sync Race Condition** - Memories deleted locally no longer reappear from cloud sync
- **Multi-device Deletion** - Deletions properly propagate across all synced devices

## [8.63.1] - 2026-01-02

### Fixed
- **Tag Deletion API Fix** (server/handlers/memory.py line 338)
  - Changed `handle_delete_by_tag` to call `storage.delete_by_tags(tags)` instead of `storage.delete_by_tag(tags)`
  - Issue: `delete_by_tag` expects a single string, but was receiving a list after `normalize_tags()`
  - Error: `'list' object has no attribute 'strip'` in CI tests
  - Impact: Tag deletion API now works correctly with normalized tag lists

## [8.63.0] - 2026-01-02

### Added
- **Delete Untagged Memories Feature** (Commits 7be6468, 9e87664, 58b8181, 80f5f72)
  - **New Bulk Operation**: Delete all memories without tags in Dashboard Manage tab
  - **Backend Endpoints**:
    - `GET /manage/untagged/count` - Returns count of untagged memories
    - `POST /manage/delete-untagged` - Deletes all untagged memories (requires confirm_count for safety)
  - **Frontend Features**:
    - New "Delete Untagged" card in Bulk Operations section
    - Real-time count display (updates on tab load)
    - Confirmation dialog before deletion
    - Smart card visibility (hidden when count is 0)
    - Proper HTTP error handling with detail fallback
  - **Impact**: Easier memory hygiene management for users with untagged content

- **SHODH Unified API Spec v1.0.0 Property Accessors** (Commit beda375)
  - **Source & Trust Properties**: `source_type` (getter/setter), `credibility` (0.0-1.0)
  - **Emotional Metadata Properties**: `emotion`, `emotional_valence` (-1.0 to 1.0), `emotional_arousal` (0.0 to 1.0)
  - **Episodic Memory Properties**: `episode_id`, `sequence_number`, `preceding_memory_id`
  - **Implementation**: All properties backed by metadata dict for automatic persistence
  - **Benefits**: Full SHODH ecosystem spec compliance, no schema migration required
  - **Compatibility**: Backward compatible with existing memories

- **SHODH Ecosystem Compatibility Documentation** (Commit d69ed2f)
  - Comprehensive README section highlighting full SHODH Unified Memory API Spec v1.0.0 compatibility
  - Table of compatible implementations (shodh-memory, shodh-cloudflare, mcp-memory-service)
  - Unified schema support details and interoperability examples
  - Links to OpenAPI 3.1.0 specification

### Fixed
- **Dashboard Delete by Tag Improvements** (Commit e59d3d1)
  - **Empty Red Toast Fix**: Frontend now checks response.ok before parsing, falls back to result.detail for HTTPException responses
  - **Tag Count Mismatch Fix** (454 vs 297): Changed from `LIKE '%tag%'` to exact tag matching using `GLOB` pattern
    - Pattern: `(',' || tags || ',') GLOB '*,tag,*'`
    - Prevents "test" from matching "testing", "test-data", etc.
  - **Case-Sensitivity Fix** (298 vs 297): Switched from LIKE (case-insensitive) to GLOB (case-sensitive)
  - **Whitespace Normalization**: Added `REPLACE(tags, ' ', '')` to remove spaces
  - **Files Changed**: `app.js` (HTTP error handling), `sqlite_vec.py` (6 methods), `cloudflare.py` (1 method)

- **Dashboard Untagged Count Display Fix** (Commit 9e87664)
  - **Problem**: data-i18n attribute replacing entire paragraph content including dynamic count span
  - **Solution**: Removed data-i18n from description paragraph to preserve `<span id="untaggedCount">` element
  - **Impact**: Untagged count now displays correctly

- **Docker Hadolint Warnings** (Commit 31d312e)
  - Consolidated RUN commands for UV installation and directory creation
  - Added hadolint ignore comments for DL3008 (apt-get version pinning)
  - Reduced Docker layers and improved build performance

- **CI Workflow Configuration** (Commits e7e41d9, 18060de, 68b6995, 3295481, 2bab616, 89e28e9, 9159271, 1491a42, f5f6622)
  - Enabled sticky comments for Claude Code integration
  - Configured Claude to post comments via gh CLI
  - Skipped 2 temporarily failing tests (timeout, missing fixture)
  - Adjusted coverage threshold to 57% (matches actual coverage)
  - Synced pyproject.toml coverage omit list with .coveragerc
  - Added defensive None checks for Cloudflare config constants
  - Fixed 15+ test failures (Queue maxsize=None, Mock completeness)

- **CI Test Infrastructure Improvements** (Issue #316)
  - **test_month_names Year Boundary Fix** (Commit 1a819b7)
    - Fixed year calculation logic for current month handling
    - Changed test logic from `current_month > 1` to `1 <= current_month` to match implementation
    - Time parser tests now pass on year boundaries
  - **Defensive None Checks for Cloudflare Vector Count** (Commit 52071f9)
    - Enhanced MockCloudflareStorage.get_stats() to return vector_count and total_vectors fields
    - Added multi-field fallback chain: `vector_count` ‚Üí `total_vectors` ‚Üí `total_memories` ‚Üí 0
    - Replaced unsafe dict access with defensive `.get()` in 5 critical paths
    - Fixed 14/18 CI test failures (83% improvement)

## [8.62.13] - 2026-01-01

### Fixed
- **HTTP-MCP Bridge API Endpoint Fix** (Based on PR #315 by @timkjr)
  - **Problem**: HTTP-MCP bridge completely broken with 405 Method Not Allowed errors
    - Bridge was using old GET endpoints (`/search?q=...`, `/search/by-tag?tags=...`)
    - Current API uses POST endpoints with JSON body payloads
    - Remote deployments using the bridge were unable to search or retrieve memories
  - **Root Cause**: Bridge code not updated when API migrated from GET to POST endpoints
  - **Solution**:
    - Updated `examples/http-mcp-bridge.js` to use POST `/search` and POST `/search/by-tag`
    - Changed from query parameters to JSON request bodies
    - Fixed response payload structure to match current API
    - Updated integration tests to verify POST endpoints
  - **Impact**: HTTP-MCP bridge now works correctly for remote MCP deployments
  - **Files Changed**:
    - `examples/http-mcp-bridge.js` (+34/-19 lines)
    - `tests/integration/test_bridge_integration.js` (+6/-1 lines)
  - **Testing**: All 9 integration tests passing (test_bridge_integration.js)

## [8.62.12] - 2026-01-01

### Fixed
- **Quality Analytics "Invalid Date" and "ID: undefined" Fix** (PR #314 by @channingwalton)
  - **Problem**: Clicking memories in Quality Analytics tab showed "Invalid Date" for created date and "undefined" for ID
    - `quality.py:memory_to_dict()` didn't include `created_at` or `memory_type` fields
    - `app.js` click handlers passed hash string instead of memory object
  - **Root Cause**: Missing fields in API response and incorrect event handler implementation
  - **Solution**:
    - Added `created_at` and `memory_type` to quality distribution API response (`quality.py`)
    - Fixed click handlers to pass memory objects instead of hash strings (`app.js`)
    - Added validation tests for required UI display fields (`test_quality_system.py`)
  - **Impact**: Quality Analytics modal now correctly displays memory metadata (creation date, type, ID)
  - **Files Changed**:
    - `src/mcp_memory_service/web/api/quality.py` (+2)
    - `src/mcp_memory_service/web/static/app.js` (+15/-2)
    - `tests/test_quality_system.py` (+8)
    - `CHANGELOG.md` (+4)

## [8.62.11] - 2025-12-31

### Fixed
- **Apple Silicon Docker Build Fix** (Issue #313 by @jwcolby)
  - **Problem**: Docker build fails on Apple Silicon (M1/M2/M3/M4) with sqlite-vec ELFCLASS32 mismatch
    - `ARG PLATFORM=linux/amd64` in Dockerfiles was never used but prevented proper architecture detection
    - Docker couldn't auto-detect host architecture on Apple Silicon Macs
  - **Root Cause**: Unused PLATFORM build argument in both Dockerfile and Dockerfile.slim
  - **Solution**: Removed unused `ARG PLATFORM=linux/amd64` from both Docker files
    - Allows Docker to properly detect and use host architecture (arm64 on Apple Silicon)
    - Maintains compatibility with all platforms through Docker's native architecture detection
  - **Impact**: Docker builds now work correctly on Apple Silicon Macs without architecture mismatches
  - **Files Changed**:
    - `tools/docker/Dockerfile` - Removed unused PLATFORM arg
    - `tools/docker/Dockerfile.slim` - Removed unused PLATFORM arg

## [8.62.10] - 2025-12-31

### Fixed
- **Document Ingestion Bug - Missing Import** (PR #312 by @feroult)
  - **Problem**: `NameError: name 'generate_content_hash' is not defined` when ingesting documents via web console
    - `generate_content_hash` was used in `web/api/documents.py` but never imported
    - Runtime error occurred when attempting document ingestion through the web interface
  - **Root Cause**: Missing import statement in documents.py API handler
  - **Solution**:
    - Added `from ...utils.hashing import generate_content_hash` to `web/api/documents.py`
    - Changed import in `document_processing.py` from `from . import generate_content_hash` to `from .hashing import generate_content_hash` to prevent circular imports
  - **Impact**: Fixes document ingestion via web console (PDF, DOCX, PPTX, TXT/MD files)
  - **Files Changed**:
    - `src/mcp_memory_service/web/api/documents.py` - Added missing import
    - `src/mcp_memory_service/utils/document_processing.py` - Fixed import to prevent circular dependency

## [8.62.9] - 2025-12-30

### Fixed
- **CI Race Condition & TypeError in Hybrid Backend** (hybrid.py)
  - **Problem 1: CI Race Condition** - "Task was destroyed but pending" warnings in GitHub Actions Linux CI (passes locally on Windows)
    - Initial sync task wasn't tracked, causing incomplete cleanup during shutdown
    - Tests would sometimes finish before background sync task was properly cancelled
  - **Problem 2: TypeError in Stats Comparison** - `.get('total_memories', 0)` fails when `total_memories` is explicitly None (not just missing)
    - Cloudflare backend can return `{'total_memories': None}` in edge cases
    - Default value `0` only applies to missing keys, not None values
  - **Solutions**:
    - Track `_initial_sync_task` reference and cancel/await during `close()` for proper cleanup
    - Change `.get('total_memories', 0)` to `.get('total_memories') or 0` to handle both missing keys AND None values
  - **Impact**: Eliminates spurious CI test failures on Linux, improves hybrid backend robustness
  - **Files Changed**:
    - `src/mcp_memory_service/storage/hybrid.py` - Added task tracking, fixed stats comparison (5 locations)

## [8.62.8] - 2025-12-30

### Fixed
- **Environment Configuration Loading Bug** (commit 626d7e8)
  - **Problem**: HTTP server wasn't loading .env configuration properly, defaulting to wrong settings (OAuth enabled, sqlite_vec backend instead of configured hybrid backend)
  - **Root Causes**:
    - `python-dotenv` was missing from dependencies in pyproject.toml, causing import failures
    - .env loading only checked single location (relative to config file), failing for source installs and different deployment scenarios
  - **Solution**:
    - Added `python-dotenv>=1.0.0` to dependencies
    - Implemented `_find_and_load_dotenv()` function with multi-location search strategy:
      1. Current working directory (highest priority)
      2. Relative to config file (for source installs)
      3. Project root markers (searches for pyproject.toml)
      4. Common Windows project paths
      5. User home directory (~/.mcp-memory/.env)
    - Uses `override=False` to respect existing environment variables
  - **Impact**: Fixes critical configuration loading issues across all deployment scenarios (development, source installs, Docker, Windows)
  - **Files Changed**:
    - `src/mcp_memory_service/config.py` - Added _find_and_load_dotenv() with comprehensive search logic
    - `pyproject.toml` - Added python-dotenv dependency

## [8.62.7] - 2025-12-30

### Fixed
- **Windows SessionStart Hook Bug Fixed in Claude Code 2.0.76+** (#160)
  - **Problem**: SessionStart hooks caused Claude Code to hang indefinitely on Windows (issue #160)
  - **Resolution**: Anthropic fixed the underlying bug in Claude Code version 2.0.76+
  - **Impact**: Windows users can now use SessionStart hooks without workarounds or manual invocation
  - **Documentation Updated**:
    - `.claude/directives/hooks-configuration.md` - Removed Windows SessionStart bug warning, updated status to FIXED
    - `CLAUDE.md` - Updated SessionStart hook references to reflect fix
    - `claude-hooks/WINDOWS-SESSIONSTART-BUG.md` - Added fix notice and version requirements
    - `docs/troubleshooting/hooks-quick-reference.md` - Updated Windows troubleshooting section
  - **User Action Required**: Upgrade to Claude Code 2.0.76+ to use SessionStart hooks on Windows
  - **Commit**: 5b0bb52 - "docs: update Windows SessionStart hook bug status - FIXED in Claude Code 2.0.76+"

## [8.62.6] - 2025-12-30

### Fixed
- **CRITICAL PRODUCTION HOTFIX: SQLite Pragmas Container Restart Bug** (#310)
  - **Problem**: SQLite pragmas (especially `busy_timeout`) were only applied during initial DB creation, causing "database is locked" errors after container restarts
  - **Solution**: Moved pragma application from `initialize()` to `_connect_and_load_extension()` so it runs on every connection
  - **Impact**: Fixes critical production locking errors in containerized deployments (Docker, Kubernetes)
  - **Technical Details**:
    - Pragmas are per-connection settings, not database-level settings
    - Must be reapplied after every connection, not just first initialization
    - Ensures `busy_timeout=10000` is set on every SQLite connection
  - **Files Changed**: `src/mcp_memory_service/storage/sqlite_vec.py` (+28/-1)
  - **Author**: @feroult (Fernando Ultremare)

## [8.62.5] - 2025-12-30

### Fixed
- **Test Suite Stability: 40 Tests Repaired** - Comprehensive test infrastructure fixes across 8 test files (commit ae49a70)
  - **Impact**: Test success rate improved from 68% (92/135) to 99% (134/135 passing)
  - **Scope**: Fixed 40 out of 43 failing tests across memory operations, storage backends, and CLI interfaces
  - **Performance**: Completed in 45 minutes using amp-bridge agent (4x faster than manual debugging)

  **Phase 1: Memory Operations & Quality (18/21 tests fixed)**
  - `test_memory_ops.py`: Fixed async/await in teardown methods, SQLite-Vec schema table creation
  - `test_content_splitting.py`: Added test-compatible wrapper methods for MemoryServer API access
  - `test_quality_system.py`: Fixed async test client initialization, router imports, storage retrieval

  **Phase 2: Hybrid Storage Backend (20/20 tests fixed)**
  - `test_hybrid_storage.py`: Fixed queue_size ‚Üí pending_operations field name, async cleanup
  - `test_background_sync.py`: Fixed sync status response structure, timestamp handling

  **Phase 3: Storage Backends & CLI (9/9 tests fixed)**
  - `test_sqlite_vec_storage.py`: Fixed KNN syntax, database schema, embedding model initialization
  - `test_hybrid_cloudflare_limits.py`: Fixed Cloudflare mock data access patterns
  - `test_cli_interfaces.py`: Fixed CLI subprocess invocation, output parsing

  **Known Issues**: 3 tests remain failing due to wandb embedding model initialization (environmental issue)
  - `test_model_config_override`: Requires wandb model download
  - `test_embedding_dimension_validation`: Requires wandb model download
  - `test_multiple_model_switching`: Requires wandb model download

### Technical Details
- **Test Infrastructure**: Added MemoryServer wrapper methods for test compatibility
- **Schema Fixes**: Ensured vec0 table creation before KNN queries
- **Async Handling**: Improved async/await patterns in test teardown
- **Mock Data**: Fixed Cloudflare backend mock data access in hybrid mode
- **Performance**: All fixes completed in single 45-minute session using amp-bridge agent

## [8.62.4] - 2025-12-29

### Fixed
- **Critical SQLite-Vec KNN Syntax Error** - Fixed semantic search queries failing with OperationalError (PR #308)
  - Issue: `sqlite3.OperationalError: A LIMIT or 'k = ?' constraint is required on vec0 knn queries`
  - Root cause: SQLite-Vec v0.1.0+ requires `k = ?` parameter syntax instead of `LIMIT ?` for KNN queries
  - Impact: Complete failure of semantic search operations (retrieve_memory, recall_memory) on sqlite-vec backend
  - Fix: Updated `SqliteVecMemoryStorage.retrieve()` and `SqliteVecMemoryStorage.recall()` to use `k = ?` parameter
  - Files changed: `src/mcp_memory_service/storage/sqlite_vec_memory_storage.py` (lines 245, 340)
  - Contributor: @feroult (Fernando Ultremare)

### Added
- **Integration Tests for KNN Syntax** - Regression prevention for sqlite-vec query syntax (commit 29c7d7e)
  - New test: `test_retrieve_knn_syntax` - Validates `k = ?` parameter in retrieve() queries
  - New test: `test_recall_knn_syntax` - Validates `k = ?` parameter in recall() queries with time expressions
  - Coverage: Explicit SQL query validation to prevent future syntax regressions
  - Files: `tests/integration/test_sqlite_vec_storage.py`

### Impact
- **Severity**: Critical (P0) - Completely broke semantic search functionality
- **Affected Users**: All users on sqlite-vec or hybrid backends (majority of installations)
- **Regression Risk**: Low - Integration tests now validate KNN syntax explicitly
- **Upgrade Note**: No action required - fix is backward compatible

### Related
- **PR #308**: Fix sqlite-vec KNN syntax error (merged)
- **Issue #309**: Documentation and CHANGELOG updates (this release)
- **SQLite-Vec v0.1.0**: Breaking change introduced `k = ?` requirement

## [8.62.3] - 2025-12-29

### Fixed
- **Critical Import Error in handle_recall_memory** - Fixed incorrect import path causing tool failure
  - Issue: Handler imported from non-existent `..utils.time_utils` module
  - Fix: Corrected to import from `...utils.time_parser` (actual module location)
  - Impact: Restored recall_memory tool functionality with time expressions
  - Functions affected: `extract_time_expression`, `parse_time_expression`
  - All tests pass (87/88 - 99% pass rate maintained)

## [8.62.2] - 2025-12-28

### Fixed
- **Consolidation Test Failures** - Resolved 4 test failures from consolidation suite (Issue #295)
  - `test_configuration_impact`: Fixed mock configuration objects to return proper quality boost settings
  - `test_access_patterns_boost_relevance`: Fixed floating-point comparison tolerance in quality score assertions
  - `test_old_access_identification`: Corrected quality score threshold triggering (0.8 ‚â• 0.7 now works correctly)
  - Root cause: Mock objects returned None for nested attributes, causing NoneType errors
  - Solution: Used MagicMock for full configuration hierarchy and adjusted assertion tolerances

- **Performance Test Failure** - Fixed background sync status field mismatch
  - `test_background_sync_with_mock`: Corrected field name `queue_size` ‚Üí `pending_operations`
  - Root cause: Test used old field name from earlier API version
  - Solution: Updated field name to match current HybridStorage implementation

- **Hybrid Storage Async/Await** - Fixed TypeErrors in cleanup methods
  - Added None-checks before calling close() on sqlite_storage and cloudflare_storage
  - Added exception handling in close() methods to prevent TypeErrors during teardown
  - Enhanced async method detection using asyncio.iscoroutinefunction()
  - Impact: Prevents TypeErrors when storage backends are None during test teardown

- **HTTP API Test Authentication** - Disabled authentication in test fixtures
  - Removed authentication middleware from test client configuration
  - Ensures proper test isolation and prevents auth-related test failures
  - Partial fix for Issue #303 (remaining API tests to be addressed separately)

- **pytest-asyncio Configuration** - Eliminated deprecation warnings
  - Added `asyncio_mode = auto` to pytest.ini configuration
  - Prevents PytestUnraisableExceptionWarning about deprecated @pytest.mark.asyncio usage
  - Ensures compatibility with pytest-asyncio 0.23.0+

### Changed
- **Test Infrastructure** - Improved error handling and cleanup patterns
  - Enhanced mock object configuration for nested attribute access
  - Improved floating-point comparison tolerance in quality score tests
  - Better async/await handling in storage cleanup methods

### Quality Metrics
- **Code Complexity**: 4.96 average (maintained 75% A-grade complexity)
- **Security**: 0 vulnerabilities (Bandit scan)
- **Test Results**: 5 previously failing tests now pass
- **Performance**: No performance regressions

### Related
- **PR #302**: Consolidation and performance test fixes
- **Issue #295**: Test failure resolution (consolidation + performance suites)
- **Issue #303**: HTTP API authentication test improvements (partial fix, follow-up needed)

## [8.62.1] - 2025-12-28

### Fixed
- **SessionEnd Hook: Read actual conversation from transcript** (claude-hooks) - PR #301 by @channingwalton
  - Fixed hook using hardcoded mock conversation data instead of real session transcript
  - Root cause: Main execution block always used mock data, never read stdin from Claude Code
  - Solution: Added `readStdinContext()` and `parseTranscript()` to read actual conversation
  - Hook now reads `{transcript_path, reason, cwd}` from stdin and parses JSONL transcript
  - Handles both string and array content formats (robust parsing)
  - Mock data preserved as fallback for manual testing only
  - **Impact**: Session consolidation memories now contain actual conversation content
  - **Testing**: 4 new integration tests (string/array content, malformed JSON, message filtering)
  - **Files Changed**: `claude-hooks/core/session-end.js`, `claude-hooks/tests/integration-test.js`

- **SessionEnd Hook: Remove arbitrary 5-topic limit** (claude-hooks) - PR #301 by @channingwalton
  - Fixed `analyzeConversation()` dropping relevant topics due to 5-topic limit
  - Root cause: Topics were limited to 5, but order-dependent matching meant specific topics (e.g., "database") were dropped when generic keywords matched first
  - Solution: Removed the `.slice(0, 5)` limit (only 10 possible topics anyway)
  - **Impact**: All matching topics are now captured in session summaries
  - **Files Changed**: `claude-hooks/core/session-end.js`

## [8.62.0] - 2025-12-27

### Added
- **Handler Integration Tests** - 100% Coverage Achievement (#299, #300)
  - New: `tests/integration/test_all_memory_handlers.py` (35 tests, 800+ lines)
  - Coverage: All 17 memory handlers now have integration tests
  - Validation: Response format checking, import path validation, success/error path coverage
  - Regression Prevention: Explicit checks for Issues #299 (import errors) and #300 (response format)
  - Test Quality: 48 response validations, 2.1:1 error-to-success test ratio
  - **Coverage Improvement**: 17.6% ‚Üí 100% handler coverage (+470% increase)

- **CI/CD Coverage Gate** - Release Quality Enforcement
  - Modified: `.github/workflows/main.yml` with pytest-cov integration
  - Added: 80% minimum coverage threshold (blocks merge if below)
  - Added: Import validation (fast-fail before test suite runs)
  - Added: Handler coverage validation (ensures all handlers tested)
  - Performance: +5 seconds overhead (11% increase, acceptable for quality gain)

- **Pre-PR Check Enhancement** - 7 to 9 Comprehensive Validations
  - Modified: `scripts/pr/pre_pr_check.sh` with 2 new critical checks
  - New Check 3: Test coverage validation with 80% threshold
  - New Check 3.5: Handler coverage validation (prevents untested handlers)
  - New Check 4: Import validation (catches Issue #299 type errors)
  - New Check 8: Final validation summary with actionable recommendations

- **Validation Scripts** - Automated Quality Enforcement
  - New: `scripts/ci/validate_imports.sh` (validates all 17 handler imports)
  - New: `scripts/validation/check_handler_coverage.py` (ensures 100% handler coverage)
  - New: `tests/integration/HANDLER_COVERAGE_REPORT.md` (detailed coverage documentation)

- **Refactoring Safety Checklist** - Prevention Framework
  - Modified: `CLAUDE.md` with 6-step mandatory checklist
  - Context: Learned from Issues #299, #300 root causes
  - Steps: Import validation ‚Üí Function extraction ‚Üí Test update ‚Üí Coverage check ‚Üí Integration test ‚Üí Regression verification

### Changed
- **Test Infrastructure Quality**
  - Test Results: 33 passed, 2 skipped (1 known import issue)
  - Handler Coverage: 17/17 handlers tested (100%)
  - Response Validations: 48 comprehensive checks
  - Error Coverage Ratio: 2.1:1 (prioritizes error path testing)

### Fixed
- **Import Error Detection** - Prevents Issue #299 Recurrence
  - CI/CD now validates all handler imports before running tests
  - Pre-PR check catches ModuleNotFoundError before merge
  - Fast-fail mechanism saves ~1-2 minutes on invalid imports

- **Response Format Validation** - Prevents Issue #300 Recurrence
  - 48 response validations ensure correct key usage
  - Tests verify success/error response structures
  - Catches KeyError bugs before production deployment

### Quality Metrics
- **Code Complexity**: 4.96 average (96% A-grade, 4% B-grade)
- **Security**: 0 vulnerabilities (Bandit scan)
- **Test Coverage**: 100% handler integration coverage (17/17)
- **CI/CD Quality**: 80% coverage gate enforced

### Prevention Guarantees
- **Import Errors** (Issue #299): Fast-fail validation in CI + Pre-PR check
- **Response Format Bugs** (Issue #300): 48 response validations in comprehensive test suite
- **Coverage Regressions**: 80% coverage gate blocks insufficient testing
- **Untested Handlers**: Handler coverage check prevents new handlers without tests

**Closes**: #299 (Import path validation), #300 (Response format validation)
**Extends**: #295 (Test suite completion - handler integration phase complete)

## [8.61.2] - 2025-12-27

### Fixed
- **CRITICAL: delete_memory KeyError** (#300)
  - Fixed handler attempting to access non-existent 'message' key in response
  - Root cause: Service returns {'success': bool, 'content_hash': str, 'error': str} but handler expected {'message': str}
  - Solution: Updated handle_delete_memory to check result['success'] and use correct response keys
  - Updated MCP tool docstring to document actual return format
  - Validation: Tested delete flow confirms fix works correctly

## [8.61.1] - 2025-12-27

### Fixed
- **CRITICAL: Import Error Hotfix** (#299)
  - Fixed import error in 5 MCP tools caused by Phase 3 refactoring
  - Problem: Relative import `..services` resolved to wrong location after handlers moved to `server/handlers/`
  - Solution: Changed to `...services` (3 dots) to correctly reach `mcp_memory_service/services/`
  - **Affected Tools** (all broken in v8.61.0):
    - update_memory_metadata
    - search_by_tag
    - delete_by_tag
    - delete_by_tags
    - delete_by_all_tags
  - **Impact**: All 5 tools now working correctly
  - **Files Changed**: `server/handlers/memory.py` (5 import locations updated)
  - **Validation**: Manual testing confirmed all imports resolve correctly

## [8.61.0] - 2025-12-27

### Changed
- **MILESTONE: Phase 3 Complete - Major Complexity Reduction Achievement** (#297)
  - Successfully refactored ALL D-level and E-level functions (4 phases, 4 commits)
  - **Average Complexity Reduction: 75.2%** across all phases
  - **Total Impact**: 400+ lines reduced from handlers, 896 new lines of well-structured utility code

  **Phase 3.1: Health Check Strategy Pattern** - E (35) ‚Üí B (7-8), 78% reduction
  - *See v8.60.0 release notes for complete Phase 3.1 details*

  **Phase 3.2: Startup Orchestrator Pattern** (Commit 016d66a)
  - Refactored `async_main` using Orchestrator Pattern
  - Complexity: **D (23) ‚Üí A (4)** - **82.6% reduction** (BEST ACHIEVEMENT)
  - Created `utils/startup_orchestrator.py` (226 lines):
    - StartupCheckOrchestrator (A/2) - Coordinate validation checks
    - InitializationRetryManager (B/6) - Handle retry logic with timeout
    - ServerRunManager (A/4) - Manage execution modes (standalone/stdio)
  - Reduced handler from 144 to 38 lines (-74%)
  - Clean separation of concerns with Single Responsibility Principle

  **Phase 3.3: Directory Ingestion Processor Pattern** (Commit e667809)
  - Refactored `handle_ingest_directory` using Processor Pattern
  - Complexity: **D (22) ‚Üí B (8)** - **64% reduction**
  - Created `utils/directory_ingestion.py` (229 lines):
    - DirectoryFileDiscovery (A-B/2-6) - File discovery and filtering
    - FileIngestionProcessor (B/3-8) - Individual file processing with stats
    - IngestionResultFormatter (A-B/1-4) - Result message formatting
  - Reduced handler from 151 to 87 lines (-42%)
  - Comprehensive analysis report: `docs/refactoring/phase-3-3-analysis.md`

  **Phase 3.4: Quality Analytics Analyzer Pattern** (Commit 32505dc)
  - Refactored `handle_analyze_quality_distribution` using Analyzer Pattern
  - Complexity: **D (21) ‚Üí A (5)** - **76% reduction** (EXCEPTIONAL)
  - Created `utils/quality_analytics.py` (221 lines):
    - QualityDistributionAnalyzer (A-B/3.75 avg) - Statistics and categorization
    - QualityRankingProcessor (A/5) - Top/bottom ranking logic
    - QualityReportFormatter (B/8) - Report formatting and presentation
  - Reduced handler from 111 to 63 lines (-43%)
  - Excellent reusability for future analytics features

  **New Architecture - 4 Utility Modules**:
  - `utils/health_check.py` - Backend health check strategies
  - `utils/startup_orchestrator.py` - Server startup orchestration
  - `utils/directory_ingestion.py` - Directory file processing
  - `utils/quality_analytics.py` - Quality analytics and reporting

  **Code Quality Achievement**:
  - **Before**: 1 E-level + 3 D-level functions (high-risk complexity)
  - **After**: ALL functions B-grade or better
    - 3 A-grade functions (complexity 4-5) - 75% of refactored code
    - 1 B-grade function (complexity 7-8)
  - **Target**: B (<10) complexity
  - **Result**: EXCEEDED - 75% now A-grade

  **Quality Validation**:
  - code-quality-guard: APPROVED FOR MERGE on all 4 phases
  - Security: 0 new vulnerabilities across all phases
  - Maintainability: Significantly improved with design patterns
  - Testability: Each component independently testable
  - Performance: No regression across all phases

## [8.60.0] - 2025-12-27

### Changed
- **Health Check Strategy Pattern Refactoring - Phase 3.1** - Critical complexity reduction (#297)
  - Implemented Strategy Pattern to isolate backend-specific health check logic
  - Created `src/mcp_memory_service/utils/health_check.py` (262 lines):
    - HealthCheckStrategy (abstract base class)
    - SqliteHealthChecker (complexity 6)
    - CloudflareHealthChecker (complexity 2)
    - HybridHealthChecker (complexity 6)
    - HealthCheckFactory (complexity 3)
    - UnknownStorageChecker (complexity 1)
  - Reduced `server/handlers/utility.py` from 356 to 174 lines (-51%, -182 lines)
  - Reduced `handle_check_database_health` from 268 to 87 lines (-68%, -181 lines)
  - **Complexity Reduction**: E (35) ‚Üí B (7-8) - 78% reduction
  - **Maintainability**: Each backend health check strategy independently testable
  - **Quality Metrics**: 0 security vulnerabilities, no performance regression
  - **Impact**: Significantly improved code organization and maintainability through separation of concerns
  - Part of Phase 3 - Complexity Reduction (follows Phase 1: v8.56.0, Phase 2: v8.59.0)

## [8.59.0] - 2025-12-27

### Changed
- **Server Architecture Refactoring - Phase 2** - Extracted handler methods into modular files (#291, #296)
  - Reduced server_impl.py from 4,294 ‚Üí 2,571 lines (-40%, -1,723 lines)
  - Extracted 29 handler methods into 5 specialized files:
    - `handlers/memory.py` (806 lines): 11 memory CRUD operations
    - `handlers/consolidation.py` (310 lines): 6 consolidation lifecycle handlers
    - `handlers/utility.py` (355 lines): 6 system utility operations
    - `handlers/documents.py` (295 lines): 3 document ingestion handlers
    - `handlers/quality.py` (293 lines): 3 quality scoring handlers
  - Improved code organization: Each handler file focuses on single responsibility
  - Maintained full backward compatibility - all existing imports work via `server_impl.py`
  - Quality metrics: Complexity A (3.02 average), health score ~85/100, 0 security issues
  - All 62 tests passing (100% pass rate maintained)
  - Developer experience improvement - easier navigation and maintenance
  - Completes Phase 2 of 3-phase server refactoring plan (Phase 1: v8.56.0, Phase 3: planned)

## [8.58.0] - 2025-12-27

### Fixed
- **Test Infrastructure Stabilization - Phase 4** - Achieved 100% test pass rate (52 tests fixed across 5 commits)
  - **Phase 4.1: Content Uniqueness & Timeouts** (11 tests fixed)
    - Added unique_content() fixture to prevent duplicate content detection errors
    - Fixed test_operations.py: 6 tests now use unique content per test
    - Fixed test_api_with_memory_service.py: 5 tests use unique content
  - **Phase 4.2 Part 1: Thread-Safety & API Format** (32 tests fixed)
    - **ONE-LINE FIX**: Added `check_same_thread=False` in sqlite_vec.py for FastAPI async operations
    - Fixed 21 thread-safety tests in test_server_handlers.py
    - Fixed 11 API format tests: Updated mocks from "memories" to "results" key
  - **Phase 4.2 Part 2: Mock Setup** (4 tests fixed)
    - Fixed test_api_tag_time_search.py: Mock type consistency (Memory vs MemoryQueryResult)
    - Fixed test_memory_service.py: Proper MemoryQueryResult wrapper usage
  - **Phase 4.3: Flaky Integration Tests** (3 tests fixed)
    - Fixed test_api_with_memory_service.py: Config-aware testing for chunking and hostname tagging
    - Tests now respect MCP_CHUNKED_STORAGE_ENABLED environment variable
  - **Phase 4.4: Pre-Existing Failures** (2 tests fixed)
    - Fixed cache_manager.py import in test_server_handlers.py
    - Addressed pre-existing failures unrelated to Phase 4 work
  - **Results**: 231/283 ‚Üí 283/283 tests passing (81.6% ‚Üí 100% pass rate)
  - **Technical Achievements**:
    - SQLite thread-safety for FastAPI async operations (single-line fix with major impact)
    - API response format evolution tracking: "memories" ‚Üí "results"
    - Mock type consistency: Memory vs MemoryQueryResult properly handled
    - Config-aware testing infrastructure for optional features

## [8.57.1] - 2025-12-26

### Fixed
- **CI/CD**: Added `server/__main__.py` to fix `python -m` execution
  - Resolves GitHub Actions failures in Docker and uvx tests
  - Regression from v8.56.0 server refactoring (server.py ‚Üí server/ package)
  - Implements --version and --help flag handling
  - Properly exits after flag processing (no server startup hang)

## [8.57.0] - 2025-12-26

### Fixed
- **Test Infrastructure Improvements** - Major test suite stabilization (+6% pass rate, 32 tests fixed)
  - **Phase 1: Critical Bug-Fixes**
    - server_impl.py: Added missing 'import time' (Line 23) - Fixed 10+ server/integration tests
    - memory_service.py: Fixed MemoryQueryResult attribute access in 3 locations - Fixed 8 tests
      - Line 432: `query_result.memory.metadata.get('tags', [])`
      - Line 438: `query_result.memory.metadata.get('memory_type', '')`
      - Line 447: `self._format_memory_response(result.memory)`
    - test_memory_service.py: Fixed test mocks to use MemoryQueryResult wrapper - Memory Service 100% (36/36)
    - tests/api/conftest.py: Created unique_content() fixture for test isolation
  - **Phase 2: mDNS & Consolidation**
    - consolidation/health.py: Added missing 'statistics' field to health check response - Fixed 5 tests
    - test_mdns.py + test_mdns_simple.py: Fixed AsyncMock setup with `__aenter__`/`__aexit__` - mDNS 100% (50/50)
  - **Phase 3: Test Isolation**
    - tests/conftest.py: Moved unique_content() fixture to parent conftest for reusability
    - tests/api/test_operations.py: Updated 18 tests with unique_content() - Fixed 14 tests
    - tests/integration/test_api_with_memory_service.py: Updated 18 tests - Fixed 14 tests
  - **Results**: 84% ‚Üí 90% pass rate (395/471 ‚Üí 398/442), 32 tests fixed, 42% error reduction
  - **Critical Systems**: Memory Service 100%, mDNS 100%, Storage 100%
  - **Impact**: Eliminated duplicate content detection errors, fixed type flow issues (MemoryQueryResult), AsyncMock properly configured

## [8.56.0] - 2025-12-26

### Changed
- **Server Architecture Refactoring - Phase 1** - Improved code maintainability and modularity (#291)
  - Extracted 453 lines from monolithic server.py into modular server/ package
  - Created 4 new modules: `client_detection.py` (76 lines), `logging_config.py` (77 lines), `environment.py` (189 lines), `cache_manager.py` (111 lines)
  - Renamed `server.py` ‚Üí `server_impl.py` to avoid package name conflict with new server/ package
  - Reduced server_impl.py from 4,613 ‚Üí 4,293 lines (-320 lines, -7%)
  - Maintained full backward compatibility - all existing imports still work via `server/__init__.py`
  - Quality metrics: Max complexity 6/10, 0 security issues, health score ~85/100
  - Developer experience improvement - makes codebase more maintainable for future development
  - Part of 3-phase refactoring plan to improve server.py architecture

## [8.55.0] - 2025-12-26

### Added
- **AI-Optimized MCP Tool Descriptions** - Enhanced LLM tool selection accuracy (#290)
  - Rewrote docstrings for 7 core MCP tools in structured format
  - New format includes: USE THIS WHEN, DO NOT USE FOR, HOW IT WORKS, RETURNS, Examples
  - Expected 30-50% reduction in incorrect tool selection by AI
  - Metrics: +360% description length, +500% use cases, +700% return detail
  - Inspired by #277 (nalyk's V2 analysis)
  - Developer experience improvement for better MCP tool consumption by LLMs
  - Tools enhanced: store_memory, recall_memory, retrieve_memory, search_by_tag, delete_by_tag, exact_match_retrieve, check_database_health

## [8.54.4] - 2025-12-26

### Fixed
- **MCP Tools**: Fixed critical bug in `check_database_health` MCP tool that prevented it from working (#288)
  - Corrected method call from non-existent `check_database_health()` to proper `health_check()` method
  - Tool now properly returns database health status and statistics

## [8.54.3] - 2025-12-25

### Fixed
- **Chunked Storage**: Fixed bug where storing content exceeding `max_content_length` would return `success: True` with "Successfully stored 0 memory chunks" when all chunks failed (e.g., due to duplicates)
  - Now correctly returns `success: False` with descriptive error message when all chunks fail
  - Added `failed_chunks` field to chunked success response for partial failures
  - Includes failure reasons in error message (e.g., "Duplicate content detected")
  - Added regression tests: `test_chunked_storage_all_chunks_fail` and `test_chunked_storage_partial_success`

## [8.54.2] - 2025-12-25

### Fixed
- **Offline Mode**: Changed from always-on to opt-in to allow first-time installations to download models (#286)
  - Offline mode now only activates when `MCP_MEMORY_OFFLINE=1` is explicitly set
  - Or when user has already set `HF_HUB_OFFLINE` or `TRANSFORMERS_OFFLINE`
  - Cache paths are still configured automatically
  - Fixes "outgoing traffic has been disabled" error during fresh installs

## [8.54.1] - 2025-12-25

### Fixed
- Installer now supports `uv` virtual environments that don't include `pip` by falling back to `uv pip` (targeting the active interpreter).

## [8.54.0] - 2025-12-23

### Added
- **Smart Auto-Capture System** - Intelligent automatic memory capture after Edit/Write/Bash operations (#282)
  - Pattern detection for 6 memory types: Decision, Error, Learning, Implementation, Important, Code
  - Bilingual support with English + German keyword recognition
  - User override markers: `#remember` / `#skip` for manual control
  - Cross-platform implementation: Node.js (primary) + PowerShell (Windows fallback)
  - Configurable via `claude-hooks/config.json` autoCapture section
  - Files: `auto-capture-patterns.js`, `auto-capture-hook.js`, `auto-capture-hook.ps1`, `README-AUTO-CAPTURE.md`
  - Installation: `python install_hooks.py --auto-capture`
  - Automatically detects important decisions, errors, learnings, implementations, and code changes
  - Reduces manual memory tagging burden while maintaining user control

### Fixed
- **Documentation**: Corrected incorrect `--http` CLI flag and port 8888 references (#283)
  - Removed non-existent `--http` flag from all documentation
  - Clarified that HTTP dashboard is a separate server (`uv run python scripts/server/run_http_server.py`)
  - Standardized port to 8000 (was incorrectly 8888 in `.env.example`)
  - Updated README, oauth-setup.md, regression-tests.md, and other docs

## [8.53.0] - 2025-12-23

### Added
- **Windows Task Scheduler Support** for HTTP server (`scripts/service/windows/`)
  - `install_scheduled_task.ps1`: Creates scheduled task that runs at user login
  - `uninstall_scheduled_task.ps1`: Removes scheduled task cleanly
  - `manage_service.ps1`: Status, start, stop, restart, logs, health commands
  - `run_http_server_background.ps1`: Wrapper with logging and automatic restart logic
  - `add_watchdog_trigger.ps1`: Adds repeating trigger (every N minutes, default 5)
  - Automatic startup at user login with skip-if-running logic
  - Watchdog trigger checks every 5 minutes (configurable)
  - Structured logging to `%LOCALAPPDATA%\mcp-memory\logs\`
  - PID file tracking for process management
  - Health endpoint verification
  - 819 lines of PowerShell automation for production-ready Windows service management
  - Addresses Windows service management gap (no native systemd/launchd equivalent)

## [8.52.2] - 2025-12-19

### Added
- **Hybrid Association Cleanup Script** (`cleanup_association_memories_hybrid.py`)
  - New maintenance script for hybrid backend users with multi-PC setups
  - Removes association memories from BOTH Cloudflare D1 AND local SQLite
  - Prevents drift-sync from restoring deleted associations across PCs
  - Features: `--skip-vectorize` flag (orphaned vectors are harmless), `--cloudflare-only`, `--local-only` modes
  - Robust Vectorize API error handling (JSON decode errors, network timeouts)
  - Automatic backup, confirmation prompts, and dry-run support
  - Documentation in `scripts/maintenance/README.md` and `docs/migration/graph-migration-guide.md`

## [8.52.1] - 2025-12-17

### Fixed
- **Windows Embedding Fallback**: Added `_HashEmbeddingModel` pure-Python fallback for DLL initialization failures
  - Treats `OSError` like `ImportError` in system hardware detection
  - Critical fix for Windows users experiencing WinError 1114 (DLL init failure)
  - Ensures embedding model always available even with missing dependencies
  - PR #281, commit 99cb72a

- **start_http_server.sh Portability**: Improved shell script compatibility and flexibility
  - Uses `MCP_HTTP_PORT` environment variable instead of hardcoded port 8889
  - Flexible Python detection with fallback (python3 ‚Üí python)
  - Auto-loads `.env` file if present in working directory
  - Commit f620041

## [8.52.0] - 2025-12-16

### Added
- **Time-of-Day Emoji Icons**: Visual indicators on all memory timestamps
  - 8 emoji icons for 3-hour segments throughout the day (üåôüåÖ‚òïüíªüçΩÔ∏è‚õÖüç∑üõèÔ∏è)
  - Icons: üåô Late Night (00-03), üåÖ Early Morning (03-06), ‚òï Morning (06-09), üíª Late Morning (09-12), üçΩÔ∏è Afternoon (12-15), ‚õÖ Late Afternoon (15-18), üç∑ Evening (18-21), üõèÔ∏è Night (21-24)
  - Position: After date on memory cards, document groups, and detail modal
  - Tooltips show time period labels on hover for accessibility
  - Dark mode support with reduced opacity (75%) and subtle grayscale filter
  - Automatic timezone detection using browser's local time
  - Performance: Negligible impact (pure CSS + simple JS, ~0.1ms per memory)
  - Implementation: ~45 lines added (31 JS + 14 CSS)

## [8.51.0] - 2025-12-16

### Added
- **Graph Database Architecture for Memory Associations** (Issue #279, PR #280)
  - **Problem Solved**: Association storage overhead (1,449 associations = 27.3% of total memories, ~2-3 MB)
  - **Solution**: SQLite graph table with recursive CTEs for efficient association storage and graph queries
  - **Performance**: 30x query improvement (150ms ‚Üí 5ms for find_connected), 97% storage reduction (500 bytes ‚Üí 50 bytes per association)
  - **Zero Breaking Changes**: Default `dual_write` mode maintains existing behavior, gradual migration supported

- **GraphStorage Class** - Dedicated storage layer for graph operations (`src/mcp_memory_service/storage/graph.py`)
  - `store_association()` - Bidirectional edge creation with JSON metadata
  - `find_connected()` - BFS traversal using recursive CTEs (1-N hops, <10ms for 1-hop)
  - `shortest_path()` - Pathfinding with cycle prevention (<15ms average)
  - `get_subgraph()` - Neighborhood extraction for visualization (<10ms radius=2)

- **Configurable Storage Modes** - Three-mode architecture for gradual migration
  - `memories_only` - Legacy behavior (associations as Memory objects, current behavior)
  - `dual_write` - Transition mode (write to both memories + graph tables, default)
  - `graph_only` - Modern mode (only graph table, 97% storage reduction)
  - Environment variable: `MCP_GRAPH_STORAGE_MODE=dual_write` (default)

- **Database Schema Migration** - `008_add_graph_table.sql`
  - New table: `memory_graph(source_hash, target_hash, similarity, connection_types, metadata)`
  - Indexes: `idx_graph_source`, `idx_graph_target`, `idx_graph_bidirectional`
  - Bidirectional edges for efficient graph traversal
  - JSON storage for flexible connection types and metadata

- **Migration & Maintenance Scripts**
  - **Backfill Script** (`scripts/maintenance/backfill_graph_table.py`)
    - Migrates existing 1,449 associations to graph table
    - Safety checks: database lock detection, disk space validation, HTTP server warnings
    - Progress reporting and duplicate detection
    - Dry-run support: `--dry-run` for preview, `--apply` for execution
    - Transaction safety with rollback on errors
  - **Cleanup Script** (`scripts/maintenance/cleanup_association_memories.py`)
    - Removes association memories after graph migration
    - Verifies graph table has matching entries before deletion
    - VACUUM operation to reclaim ~2-3 MB storage
    - Interactive confirmation with `--force` bypass
    - Dry-run support: `--dry-run` for preview

- **Comprehensive Test Suite** - 90%+ coverage for graph functionality
  - **GraphStorage Tests** (`tests/storage/test_graph_storage.py`) - 22 unit tests, all passing
    - Coverage: store, find_connected, shortest_path, get_subgraph
    - Edge cases: cycles, empty inputs, self-loops, None values
    - Performance benchmarks: <10ms validation for 1-hop queries
  - **Storage Mode Tests** (`tests/consolidation/test_graph_modes.py`) - 4 passing, 7 scaffolded for Phase 2
    - Config validation, basic operations, storage size comparison
    - Mode switching tests for consolidator integration (Phase 2)
  - **Test Fixtures** (`tests/storage/conftest.py`)
    - Graph-specific fixtures: temp_graph_db, graph_storage, sample_graph_data
    - Four graph topologies: linear chain, cycle, diamond, hub

- **Documentation** - Comprehensive guides for users and developers
  - Architecture specification: `docs/architecture/graph-database-design.md`
  - Migration guide: `docs/migration/graph-migration-guide.md`
  - Configuration examples in `.env.example`

### Changed
- **Consolidator Integration** (`src/mcp_memory_service/consolidation/consolidator.py`) - Mode-based dispatcher
  - GraphStorage initialization with automatic db_path detection (hybrid backend support)
  - Mode switching dispatcher: routes associations to memories, graph, or both based on `GRAPH_STORAGE_MODE`
  - Backward compatible: existing association creation continues working unchanged
  - +130 lines added for graph integration

- **Configuration System** (`src/mcp_memory_service/config.py`) - Graph storage mode configuration
  - New config: `GRAPH_STORAGE_MODE` with validation (memories_only|dual_write|graph_only)
  - Default: `dual_write` for backward compatibility
  - Startup logging for selected mode
  - +24 lines added for configuration

### Performance Metrics

**Query Performance** (real-world deployment, 1,449 associations):

| Query Type | Before (Memories) | After (Graph Table) | Improvement |
|------------|------------------|---------------------|-------------|
| Find Connected (1-hop) | 150ms | 5ms | **30x faster** |
| Find Connected (3-hop) | 800ms | 25ms | **32x faster** |
| Shortest Path | 1,200ms | 15ms | **80x faster** |
| Get Subgraph (radius=2) | N/A | 10ms | **New capability** |

**Storage Efficiency** (1,449 associations):

| Storage Mode | Database Size | Per Association | Reduction |
|--------------|---------------|----------------|-----------|
| memories_only (baseline) | 2.8 MB | 500 bytes | 0% |
| dual_write | 2.88 MB | ~515 bytes | -3% (temporary) |
| graph_only | 144 KB | 50 bytes | **97% reduction** |

**Test Suite Performance**:
- 26 passed, 7 xfailed (Phase 2), 0.25s execution time
- GraphStorage class: ~90-95% coverage

### Migration Path

**For Existing Users** (3-step process):
1. Upgrade to v8.51.0 (default: `dual_write` mode, zero breaking changes)
2. Run backfill script: `python scripts/maintenance/backfill_graph_table.py --apply`
3. Switch to graph_only: `export MCP_GRAPH_STORAGE_MODE=graph_only`
4. Optional cleanup: `python scripts/maintenance/cleanup_association_memories.py`

**For New Installations**:
- Start with `graph_only` mode for immediate benefits

**Rollback Support**:
- Switch back to `memories_only` mode at any time
- Graph table preserved for future re-enablement

### Technical Details

**Files Created** (7):
- `src/mcp_memory_service/storage/graph.py` (383 lines) - GraphStorage class
- `src/mcp_memory_service/storage/migrations/008_add_graph_table.sql` (18 lines) - Schema migration
- `scripts/maintenance/backfill_graph_table.py` (286 lines) - Migration script
- `scripts/maintenance/cleanup_association_memories.py` (542 lines) - Cleanup script
- `tests/storage/conftest.py` (142 lines) - Test fixtures
- `tests/storage/test_graph_storage.py` (518 lines) - GraphStorage tests
- `tests/consolidation/test_graph_modes.py` (263 lines) - Mode switching tests

**Files Modified** (3):
- `src/mcp_memory_service/config.py` (+24 lines) - Configuration
- `.env.example` (+24 lines) - Documentation
- `src/mcp_memory_service/consolidation/consolidator.py` (+130 lines) - Integration

**Total**: 2,652 insertions(+), 26 deletions(-)

**Recursive CTE Implementation** (find_connected):
```sql
WITH RECURSIVE connected_memories(hash, distance, path) AS (
    SELECT ?, 0, ?
    UNION ALL
    SELECT mg.target_hash, cm.distance + 1, cm.path || ',' || mg.target_hash
    FROM connected_memories cm
    JOIN memory_graph mg ON cm.hash = mg.source_hash
    WHERE cm.distance < ? AND instr(cm.path, mg.target_hash) = 0
)
SELECT DISTINCT hash, distance FROM connected_memories WHERE distance > 0;
```

**Key Features**:
- Bidirectional BFS traversal
- Cycle prevention via path tracking
- Single SQL query (no round-trips)
- Indexed lookups: O(log N) vs O(N) table scans

### Real-World Validation

**Production Deployment** (December 14, 2025):
- Consolidation system created 343 associations automatically
- Backfill migrated 1,435 associations (14 skipped due to missing metadata)
- Query latency: <10ms for all 1-hop queries
- Storage overhead: ~144 KB for graph table vs ~2.8 MB as memories (97% reduction)

### Future Enhancements

**Phase 2** (v8.52.0):
- REST API endpoints: `/api/graph/connected/{hash}`, `/api/graph/path/{hash1}/{hash2}`
- Graph visualization in web UI
- Complete consolidator mode switching (7 xfail tests to pass)

**Phase 3** (v9.0+):
- rustworkx integration for advanced graph analytics (PageRank, community detection)
- Pattern matching (Cypher-like queries)
- Temporal graph queries

### Related Issues
- Closes #279 - Graph Database Architecture for Memory Associations
- Related to #268 - Memory Quality System (uses association counts for quality boost)
- Related to consolidation system (creates 343 associations in single run)

